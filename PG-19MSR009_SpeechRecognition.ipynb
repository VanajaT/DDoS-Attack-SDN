{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VanajaT/DDoS-Attack-SDN/blob/main/PG-19MSR009_SpeechRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMsQ_V9nqI6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77052e1e-bc13-4b97-858e-e63924b0a6ad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaDHeAPEGfU5",
        "outputId": "06e97b34-59f4-43e3-c2f9-e8a881e8c09f"
      },
      "source": [
        "import librosa\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "print(os.listdir('/content/drive/MyDrive/speechdata/'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cat', 'bed', 'happy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdPnzlUDEbw0"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "def get_labels(path='/content/drive/MyDrive/speechdata/'):\n",
        "    labels = os.listdir(path)\n",
        "    label_indices = np.arange(0, len(labels))\n",
        "    return labels, label_indices, to_categorical(label_indices)\n",
        "\n",
        "\n",
        "def wav2mfcc(file_path, max_len=11):\n",
        "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
        "    wave = wave[::3]\n",
        "    mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
        "\n",
        "    if (max_len > mfcc.shape[1]):\n",
        "        pad_width = max_len - mfcc.shape[1]\n",
        "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "\n",
        "    else:\n",
        "        mfcc = mfcc[:, :max_len]\n",
        "\n",
        "    return mfcc\n",
        "\n",
        "\n",
        "def save_data_to_array(path='/content/drive/MyDrive/speechdata/', max_len=11):\n",
        "    labels, _, _ = get_labels(path)\n",
        "\n",
        "    for label in labels:\n",
        "        # Init mfcc vectors\n",
        "        mfcc_vectors = []\n",
        "\n",
        "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
        "        for wavfile in tqdm(wavfiles, \"Saving vectors of label - '{}'\".format(label)):\n",
        "            mfcc = wav2mfcc(wavfile, max_len=max_len)\n",
        "            mfcc_vectors.append(mfcc)\n",
        "        np.save(label + '.npy', mfcc_vectors)\n",
        "\n",
        "\n",
        "def get_train_test(split_ratio=0.6, random_state=42):\n",
        "    labels, indices, _ = get_labels('/content/drive/MyDrive/speechdata/')\n",
        "\n",
        "    X = np.load(labels[0] + '.npy')\n",
        "    y = np.zeros(X.shape[0])\n",
        "\n",
        "    # Append all of the dataset into one single array, same goes for y\n",
        "    for i, label in enumerate(labels[1:]):\n",
        "        x = np.load(label + '.npy')\n",
        "        X = np.vstack((X, x))\n",
        "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
        "\n",
        "    assert X.shape[0] == len(y)\n",
        "\n",
        "    return train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "def prepare_dataset(path='/content/drive/MyDrive/speechdata/'):\n",
        "    labels, _, _ = get_labels(path)\n",
        "    data = {}\n",
        "    for label in labels:\n",
        "        data[label] = {}\n",
        "        data[label]['path'] = [path  + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
        "\n",
        "        vectors = []\n",
        "\n",
        "        for wavfile in data[label]['path']:\n",
        "            wave, sr = librosa.load(wavfile, mono=True, sr=None)\n",
        "            # Downsampling\n",
        "            wave = wave[::3]\n",
        "            mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
        "            vectors.append(mfcc)\n",
        "\n",
        "        data[label]['mfcc'] = vectors\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_dataset(path='/content/drive/MyDrive/speechdata/'):\n",
        "    data = prepare_dataset(path)\n",
        "\n",
        "    dataset = []\n",
        "\n",
        "    for key in data:\n",
        "        for mfcc in data[key]['mfcc']:\n",
        "            dataset.append((key, mfcc))\n",
        "\n",
        "    return dataset[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOPswEeIcmrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df8c40eb-81f7-43a1-d31e-aa5ace74f56f"
      },
      "source": [
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Second dimension of the feature is dim2\n",
        "feature_dim_2 = 11\n",
        "\n",
        "# Save data to array file first\n",
        "save_data_to_array(max_len=feature_dim_2)\n",
        "\n",
        "# # Loading train set and test set\n",
        "X_train, X_test, y_train, y_test = get_train_test()\n",
        "\n",
        "# # Feature dimension\n",
        "feature_dim_1 = 20\n",
        "channel = 1\n",
        "epochs = 50\n",
        "batch_size = 10\n",
        "verbose = 1\n",
        "num_classes = 3\n",
        "\n",
        "# Reshaping to perform 2D convolution\n",
        "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
        "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
        "\n",
        "y_train_hot = to_categorical(y_train)\n",
        "y_test_hot = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving vectors of label - 'cat': 100%|██████████| 20/20 [00:13<00:00,  1.50it/s]\n",
            "Saving vectors of label - 'bed': 100%|██████████| 20/20 [00:13<00:00,  1.49it/s]\n",
            "Saving vectors of label - 'happy': 100%|██████████| 20/20 [00:13<00:00,  1.53it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ico5dxn2cmrq"
      },
      "source": [
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
        "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
        "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adadelta(),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Predicts one sample\n",
        "def predict(filepath, model):\n",
        "    sample = wav2mfcc(filepath)\n",
        "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
        "    return get_labels()[0][\n",
        "            np.argmax(model.predict(sample_reshaped))\n",
        "    ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoI_PSWGcmrt"
      },
      "source": [
        "# Building The Model Then Training it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FX9s5K4cmru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1827885-2202-4e0e-8871-3718f4145aab"
      },
      "source": [
        "model = get_model()\n",
        "model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 7.6907 - accuracy: 0.1944 - val_loss: 3.5322 - val_accuracy: 0.3750\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.7732 - accuracy: 0.3611 - val_loss: 3.5093 - val_accuracy: 0.3750\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 5.9341 - accuracy: 0.2500 - val_loss: 3.4923 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 6.3046 - accuracy: 0.3333 - val_loss: 3.4700 - val_accuracy: 0.3333\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 5.6904 - accuracy: 0.1944 - val_loss: 3.4532 - val_accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 5.7977 - accuracy: 0.2500 - val_loss: 3.4325 - val_accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 6.9609 - accuracy: 0.3056 - val_loss: 3.4109 - val_accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 5.9243 - accuracy: 0.3333 - val_loss: 3.4002 - val_accuracy: 0.3333\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 6.8581 - accuracy: 0.2222 - val_loss: 3.3827 - val_accuracy: 0.3333\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 6.9259 - accuracy: 0.2222 - val_loss: 3.3656 - val_accuracy: 0.3333\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 6.1588 - accuracy: 0.2778 - val_loss: 3.3518 - val_accuracy: 0.2917\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 5.0525 - accuracy: 0.4722 - val_loss: 3.3393 - val_accuracy: 0.2917\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 7.0318 - accuracy: 0.3056 - val_loss: 3.3283 - val_accuracy: 0.2917\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.9048 - accuracy: 0.3611 - val_loss: 3.3178 - val_accuracy: 0.2917\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 6.5755 - accuracy: 0.2778 - val_loss: 3.3025 - val_accuracy: 0.2917\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.7598 - accuracy: 0.3611 - val_loss: 3.2947 - val_accuracy: 0.2500\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.8364 - accuracy: 0.3889 - val_loss: 3.2811 - val_accuracy: 0.2500\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 5.0593 - accuracy: 0.3889 - val_loss: 3.2707 - val_accuracy: 0.2500\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 5.1308 - accuracy: 0.3056 - val_loss: 3.2617 - val_accuracy: 0.2500\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 5.8799 - accuracy: 0.3333 - val_loss: 3.2510 - val_accuracy: 0.2500\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.3251 - accuracy: 0.3889 - val_loss: 3.2457 - val_accuracy: 0.2500\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.6726 - accuracy: 0.3056 - val_loss: 3.2369 - val_accuracy: 0.2500\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.0329 - accuracy: 0.2500 - val_loss: 3.2307 - val_accuracy: 0.2500\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 5.0104 - accuracy: 0.3611 - val_loss: 3.2223 - val_accuracy: 0.2917\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.8640 - accuracy: 0.2778 - val_loss: 3.2136 - val_accuracy: 0.2917\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 5.6328 - accuracy: 0.2500 - val_loss: 3.2058 - val_accuracy: 0.2917\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 5.5324 - accuracy: 0.2500 - val_loss: 3.1966 - val_accuracy: 0.2500\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 6.2467 - accuracy: 0.3611 - val_loss: 3.1913 - val_accuracy: 0.2500\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 5.9241 - accuracy: 0.1944 - val_loss: 3.1902 - val_accuracy: 0.2500\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 4.2499 - accuracy: 0.3611 - val_loss: 3.1861 - val_accuracy: 0.2500\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.7237 - accuracy: 0.3611 - val_loss: 3.1874 - val_accuracy: 0.2500\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 5.7216 - accuracy: 0.2222 - val_loss: 3.1847 - val_accuracy: 0.2500\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 5.0503 - accuracy: 0.5556 - val_loss: 3.1773 - val_accuracy: 0.2500\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 7.9368 - accuracy: 0.1389 - val_loss: 3.1704 - val_accuracy: 0.2500\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.9623 - accuracy: 0.3056 - val_loss: 3.1665 - val_accuracy: 0.2500\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 7.1259 - accuracy: 0.3056 - val_loss: 3.1693 - val_accuracy: 0.2500\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 5.7753 - accuracy: 0.3056 - val_loss: 3.1523 - val_accuracy: 0.2500\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 5.4478 - accuracy: 0.2500 - val_loss: 3.1540 - val_accuracy: 0.2500\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 5.7498 - accuracy: 0.3056 - val_loss: 3.1542 - val_accuracy: 0.2500\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.9508 - accuracy: 0.4167 - val_loss: 3.1450 - val_accuracy: 0.2500\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.6308 - accuracy: 0.2778 - val_loss: 3.1372 - val_accuracy: 0.2500\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 5.8995 - accuracy: 0.3056 - val_loss: 3.1359 - val_accuracy: 0.2917\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 4.6380 - accuracy: 0.2778 - val_loss: 3.1298 - val_accuracy: 0.2917\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 3.8703 - accuracy: 0.4444 - val_loss: 3.1277 - val_accuracy: 0.2917\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.4874 - accuracy: 0.2222 - val_loss: 3.1179 - val_accuracy: 0.2917\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.3626 - accuracy: 0.3333 - val_loss: 3.1074 - val_accuracy: 0.2917\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 3.7701 - accuracy: 0.3889 - val_loss: 3.0972 - val_accuracy: 0.2917\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.8245 - accuracy: 0.3611 - val_loss: 3.1007 - val_accuracy: 0.2917\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.7405 - accuracy: 0.3333 - val_loss: 3.0963 - val_accuracy: 0.2917\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 5.3815 - accuracy: 0.2500 - val_loss: 3.0889 - val_accuracy: 0.2917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9999ea1c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR_96kDncmr1"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G77VYMsncmr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c2221d-9111-44c3-fc2f-a1e1bdbddf7a"
      },
      "source": [
        "print(predict('/content/drive/MyDrive/speechdata/bed/0fa1e7a9_nohash_0.wav', model=model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bed\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}